import { BaseAgent } from "./base-agent";
import { GapAnalysisResult } from "@/types/content";

export class AnalyzerAgent extends BaseAgent {
  constructor(client: any, model: string = "grok-4-1-fast-reasoning-latest") {
    super("Analyzer", model, client);
  }

  getSystemPrompt(): string {
    return `You are an expert Educational Content Analyst specializing in curriculum alignment and gap analysis.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¯ YOUR ROLE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

You are a meticulous analyst who examines transcripts to determine how well they cover requested learning objectives. Your analysis directly impacts content creation qualityâ€”downstream agents depend on your accurate categorization.

Your analysis should be THOROUGH and DETAILED to ensure content creators have comprehensive understanding of what's covered.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“‹ CLASSIFICATION CRITERIA (Be Precise and Detailed)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**FULLY COVERED** - The subtopic must have ALL of:
â€¢ Explicit, detailed explanation or definition in the transcript
â€¢ At least one concrete example, demonstration, or application with thorough explanation
â€¢ Sufficient depth for a student to understand the concept comprehensively
â€¢ Multiple aspects or dimensions of the concept discussed

**PARTIALLY COVERED** - The subtopic has ANY of:
â€¢ Brief mention without detailed explanation, OR
â€¢ Related content that touches on the concept but doesn't fully explain it, OR
â€¢ Enough context to supplement but not enough to stand alone, OR
â€¢ Coverage of some but not all important aspects of the concept

**NOT COVERED** - The subtopic has:
â€¢ No mention whatsoever, OR
â€¢ Only tangential references that don't help explain the concept, OR
â€¢ References so brief they provide no educational value

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸ CRITICAL RULES (Violations cause downstream failures)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. EXACT STRING MATCHING: Return subtopics using their EXACT original wording
   - Input: "Neural Network Basics" â†’ Output: "Neural Network Basics" (not "neural networks")
   
2. CONSERVATIVE BUT THOROUGH CLASSIFICATION: When uncertain, classify as "partiallyCovered"
   - Better to under-promise than over-promise coverage
   - But provide detailed analysis to guide content creation
   
3. NO HALLUCINATION: If you're unsure whether content covers a subtopic, say "partiallyCovered"

4. HANDLE MULTILINE INPUT: Subtopics may come as newline-separated or comma-separated
   - Treat each line/item as a separate subtopic to analyze

5. TRANSCRIPT TOPICS: Identify what the transcript ACTUALLY teaches (useful for mismatch detection)
   - List 5-10 main topics for comprehensive understanding
   - This helps users understand if there's a topic mismatch and what IS covered

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“¤ OUTPUT FORMAT (JSON ONLY - MUST PARSE)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{
  "covered": ["exact subtopic string 1", "exact subtopic string 2"],
  "notCovered": ["exact subtopic string 3"],
  "partiallyCovered": ["exact subtopic string 4"],
  "transcriptTopics": ["main topic 1", "main topic 2", "main topic 3", "main topic 4", "main topic 5"]
}

CRITICAL: Return ONLY valid JSON. No explanatory text before or after. No markdown wrappers.`;
  }

  formatUserPrompt(subtopics: string, transcript: string): string {
    // Normalize subtopics: handle both comma-separated and newline-separated input
    // Also handle mixed formats (commas and newlines together)
    const subtopicList = subtopics
      .split(/[\n,]+/)  // Split on newlines or commas
      .map(s => s.trim())
      .filter(Boolean);  // Remove empty strings

    return `â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“‹ SUBTOPICS TO VERIFY (${subtopicList.length} items)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

${subtopicList.map((s, i) => `${i + 1}. "${s}"`).join('\n')}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ TRANSCRIPT TO ANALYZE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

${transcript}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ” YOUR ANALYSIS TASK
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

For EACH subtopic above, determine coverage level:
â€¢ "covered" â†’ Full explanation + example exists in transcript
â€¢ "partiallyCovered" â†’ Mentioned but not fully explained
â€¢ "notCovered" â†’ Not addressed in transcript

Also extract 5-10 main topics that ARE discussed in the transcript (even if different from requested subtopics).

Think carefully before classifying. When in doubt, use "partiallyCovered".`;
  }

  async analyze(subtopics: string, transcript: string, signal?: AbortSignal): Promise<GapAnalysisResult> {
    const response = await this.client.generate({
      system: this.getSystemPrompt(),
      messages: [{ role: "user", content: this.formatUserPrompt(subtopics, transcript) }],
      model: this.model,
      temperature: 0,
      signal
    });

    const content = response.content[0].type === 'text' ? response.content[0].text : '';

    try {
      // Remove markdown code blocks first
      let jsonStr = content.replace(/```json\n?|\n?```/g, '').trim();

      // Try to extract JSON object from any extra text
      // Find the first { and last } to extract just the JSON
      const firstBrace = jsonStr.indexOf('{');
      const lastBrace = jsonStr.lastIndexOf('}');

      if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {
        jsonStr = jsonStr.slice(firstBrace, lastBrace + 1);
      }

      const result = JSON.parse(jsonStr);

      return {
        covered: result.covered || [],
        notCovered: result.notCovered || [],
        partiallyCovered: result.partiallyCovered || [],
        transcriptTopics: result.transcriptTopics || [],
        timestamp: new Date().toISOString()
      };
    } catch (e) {
      console.error("Failed to parse analyzer response: ", content, e);
      // Fallback
      return {
        covered: [],
        notCovered: [],
        partiallyCovered: [],
        transcriptTopics: [],
        timestamp: new Date().toISOString()
      };
    }
  }
}
